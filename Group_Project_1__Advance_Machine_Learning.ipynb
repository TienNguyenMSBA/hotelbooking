{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TienNguyenMSBA/hotelbooking/blob/main/Group_Project_1__Advance_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1e9e36",
      "metadata": {
        "id": "bd1e9e36"
      },
      "source": [
        "### README\n",
        "\n",
        "This notebook contains the code to predict final demand of a hotel booking data using different models:\n",
        "\n",
        "1. Advance Booking (Pick-up) Models (Additive and Multiplicative)\n",
        "2. Advance Booking Feedforward Neural Network Models\n",
        "3. Time Series LSTM Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c74306fb-bbfd-45b8-a330-8d93573a5d0d",
      "metadata": {
        "id": "c74306fb-bbfd-45b8-a330-8d93573a5d0d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ew42rQkVe_t",
      "metadata": {
        "id": "5ew42rQkVe_t"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "file_path = '/content/hotel_bookings.csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca087e8c-0d46-4b18-9dbc-026884e56a45",
      "metadata": {
        "id": "ca087e8c-0d46-4b18-9dbc-026884e56a45"
      },
      "source": [
        "##### Read the data (csv file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9d79e9",
      "metadata": {
        "id": "1b9d79e9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"hotel_bookings.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u70gT3bDD8mX",
      "metadata": {
        "id": "u70gT3bDD8mX"
      },
      "source": [
        "##### **1. Pick-up models**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dcd20d-276b-4597-b1bb-bacc77c5f521",
      "metadata": {
        "id": "f6dcd20d-276b-4597-b1bb-bacc77c5f521"
      },
      "source": [
        "##### Convert date columns to datetime for filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c314852-e4c6-467f-9122-d53c4a05358f",
      "metadata": {
        "id": "3c314852-e4c6-467f-9122-d53c4a05358f"
      },
      "outputs": [],
      "source": [
        "## Define features (X) and target (y)\n",
        "feature_cols = [\"days_prior\", \"bookings_on_hand\", \"day_of_week\", \"month\", \"naive_forecast\"]\n",
        "target_col = \"final_demand\"\n",
        "\n",
        "def convert_datetime(df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = pd.to_datetime(df[col])\n",
        "    return df\n",
        "\n",
        "date_columns = [\"stay_date\", \"booking_date\"]\n",
        "df = convert_datetime(df, date_columns)\n",
        "\n",
        "## Create feature columns used by models and aggregations\n",
        "df[\"day_of_week\"] = df[\"stay_date\"].dt.day_name()\n",
        "df[\"month\"] = df[\"stay_date\"].dt.month\n",
        "df['days_prior_range'] = pd.cut(df['days_prior'], bins=[0,7,14,21,30], labels=['1-7','8-14','15-21','22-30'], right=True)\n",
        "df['remaining_demand'] = df['final_demand'] - df['bookings_on_hand']\n",
        "\n",
        "## Create naive forecast based on previous year's final_demand for same hotel and stay_date\n",
        "df['stay_date'] = pd.to_datetime(df['stay_date'])\n",
        "df = df.sort_values(['hotel_code', 'stay_date'])\n",
        "# Create a shifted date column for lookup\n",
        "df['prev_year_date'] = df['stay_date'] - pd.DateOffset(years=1)\n",
        "# Build a mapping from (hotel_code, date) → final_demand\n",
        "key_to_demand = dict(zip(zip(df['hotel_code'], df['stay_date']), df['final_demand']))\n",
        "# Lookup previous year's value efficiently\n",
        "df['naive_forecast'] = [\n",
        "    key_to_demand.get((h, prev_date)) for h, prev_date in zip(df['hotel_code'], df['prev_year_date'])\n",
        "]\n",
        "# Drop missing\n",
        "df = df.dropna(subset=['naive_forecast'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441a9bc0-b7fb-454e-8ecf-8c99cecd831a",
      "metadata": {
        "id": "441a9bc0-b7fb-454e-8ecf-8c99cecd831a"
      },
      "source": [
        "##### **Helper functions** for pick-up models\n",
        "- Additive model (bookings_on_hand + average remaining demand)\n",
        "- Multiplicative model (bookings_on_hand/average booking rate)\n",
        "- Calculate error metrics (MAE, MAPE)\n",
        "- Compute MASE using naive forecast (previous year). For example, the naive forecast for stay date Apr 1st, 2010 is the actual demand of Apr 2nd, 2009\n",
        "- Add the forecast to the validation set, using days_prior 1-30\n",
        "- Print out the forecasting errors grouped by hotel code, days_prior range, and month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb2edde-db53-40ec-825d-f6602f19df6e",
      "metadata": {
        "id": "aeb2edde-db53-40ec-825d-f6602f19df6e"
      },
      "outputs": [],
      "source": [
        "## Additive model (bookings_on_hand + average remaining demand)\n",
        "def add_model(df):\n",
        "    df = df.copy()\n",
        "    df = df[df['days_prior'].between(1,30)]\n",
        "    df['average_remaining_demand'] = df.groupby(['hotel_code', 'days_prior'], sort=False)[\n",
        "        'remaining_demand'].transform(np.mean)\n",
        "    df['forecast'] = df['bookings_on_hand'] + df['average_remaining_demand']\n",
        "    return df\n",
        "\n",
        "## Multiplicative model (bookings_on_hand/average booking rate)\n",
        "def multi_model(df):\n",
        "    df = df.copy()\n",
        "    df = df[df['days_prior'].between(1,30)]\n",
        "    df['booking_rate'] = df['bookings_on_hand'] / df['final_demand']\n",
        "    df['average_booking_rate'] = df.groupby(['hotel_code', 'days_prior'], sort=False)['booking_rate'].transform(np.mean)\n",
        "    df['forecast'] = df['bookings_on_hand'] / df['average_booking_rate']\n",
        "\n",
        "    # Handle inf/nan\n",
        "    df['forecast'] = df['forecast'].replace([np.inf, -np.inf], np.nan)\n",
        "    df['forecast'] = df['forecast'].fillna(df['bookings_on_hand'])\n",
        "    return df\n",
        "\n",
        "## Calculate error metrics (MAE, MAPE)\n",
        "def compute_errors(df, naive_df=None):\n",
        "    df = df.copy()\n",
        "    df['error'] = df['final_demand'] - df['forecast']\n",
        "    df['abs_error'] = df['error'].abs()\n",
        "    df['mae'] = df['abs_error']\n",
        "    df['mape'] = df['abs_error'] / df['final_demand'].replace(0, np.nan) * 100\n",
        "\n",
        "        # --- Compute MASE ---\n",
        "    if 'naive_forecast' in df.columns:\n",
        "        # MAE of model\n",
        "        mae_model = df['abs_error'].mean()\n",
        "\n",
        "        # MAE of naive forecast\n",
        "        df['naive_error'] = (df['final_demand'] - df['naive_forecast']).abs()\n",
        "        mae_naive = df['naive_error'].mean()\n",
        "\n",
        "        # Scaled error\n",
        "        df['mase'] = df['abs_error'] / mae_naive if mae_naive != 0 else np.nan\n",
        "    else:\n",
        "        df['mase'] = np.nan\n",
        "    return df\n",
        "\n",
        "\n",
        "## Function for adding the forecast to the validation set, using days_prior 1-30\n",
        "def validation(train, val, pickup, model_type='add'):\n",
        "        # Merge pickup info by days_prior + hotel_code\n",
        "    val = val[val['days_prior'].between(1, 30)].copy()\n",
        "    booking_info = train[['days_prior', 'hotel_code', pickup]].drop_duplicates()\n",
        "    forecast = val.merge(booking_info, on=['hotel_code', 'days_prior'], how='left')\n",
        "\n",
        "    # Compute forecast based on model type\n",
        "    if model_type == 'add':\n",
        "        forecast['forecast'] = forecast['bookings_on_hand'] + forecast[pickup].fillna(0)\n",
        "    elif model_type == 'multi':\n",
        "        forecast['forecast'] = (forecast['bookings_on_hand'] / forecast[pickup].replace(0, np.nan))\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model_type. Use 'add' or 'multi'.\")\n",
        "\n",
        "    # Compute errors relative to naive model (previous year's actuals)\n",
        "    forecast = compute_errors(forecast, naive_df=train)\n",
        "\n",
        "    return forecast\n",
        "\n",
        "## Print out the forecasting errors grouped by hotel code, days_prior range, and month\n",
        "def summarize_errors(df):\n",
        "    # Overall metrics\n",
        "    print(f\"\\nOVERALL METRICS:\")\n",
        "    print(f\"MAE:  {df['mae'].mean():.2f}\")\n",
        "    print(f\"MAPE: {df['mape'].mean():.2f}%\")\n",
        "    print(f\"MASE: {df['mase'].mean():.2f}\")\n",
        "\n",
        "    # Group by month and hotel\n",
        "    monthly_errors = (\n",
        "        df.groupby(['hotel_code', 'month'])\n",
        "        [['mae', 'mape', 'mase']]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Group by days-prior range and hotel\n",
        "    daysprior_errors = (\n",
        "        df.groupby(['hotel_code', 'days_prior_range'])\n",
        "        [['mae', 'mape', 'mase']]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    for hotel in df['hotel_code'].unique():\n",
        "        print(f\"\\n===== {hotel} =====\")\n",
        "        print(\"\\nAverage Errors by Month:\")\n",
        "        print(\n",
        "            monthly_errors[monthly_errors['hotel_code'] == hotel]\n",
        "            .drop(columns='hotel_code')\n",
        "            .rename(columns={'month': 'Month', 'mae': 'Average MAE', 'mape': 'Average MAPE', 'mase': 'Average MASE'})\n",
        "            .to_string(index=False)\n",
        "        )\n",
        "\n",
        "        print(\"\\nAverage Errors by Days-Prior Range:\")\n",
        "        print(\n",
        "            daysprior_errors[daysprior_errors['hotel_code'] == hotel]\n",
        "            .drop(columns='hotel_code')\n",
        "            .rename(columns={'days_prior_range': 'Days-Prior Range', 'mae': 'Average MAE', 'mape': 'Average MAPE', 'mase': 'Average MASE'})\n",
        "            .to_string(index=False)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3fe54a2",
      "metadata": {
        "id": "a3fe54a2"
      },
      "source": [
        "##### Apply the functions above to the dataframe in training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9411ecff",
      "metadata": {
        "id": "9411ecff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fdb0a3df-6ca6-4130-8c5e-d1c347b16c42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'add_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4033002114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Train the data and compute errors in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'add_model' is not defined"
          ]
        }
      ],
      "source": [
        "## Train the data and compute errors in train\n",
        "train_add = add_model(train)\n",
        "train_add = compute_errors(train_add)\n",
        "\n",
        "train_multi = multi_model(train)\n",
        "train_multi = compute_errors(train_multi)\n",
        "\n",
        "## Validate models with test/validation data\n",
        "val_add = validation(train_add, val, 'average_remaining_demand', model_type='add')\n",
        "val_multi = validation(train_multi, val, 'average_booking_rate', model_type='multi')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a81681",
      "metadata": {
        "id": "a1a81681"
      },
      "source": [
        "#####"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c075618",
      "metadata": {
        "id": "9c075618"
      },
      "source": [
        "##### Results from ADDITIVE model with forcasting errors below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3472792",
      "metadata": {
        "id": "c3472792"
      },
      "outputs": [],
      "source": [
        "summarize_errors(val_add)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bd5959",
      "metadata": {
        "id": "17bd5959"
      },
      "source": [
        "##### Results from MULTIPLICATIVE model with forcasting errors below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6108e6f2",
      "metadata": {
        "id": "6108e6f2"
      },
      "outputs": [],
      "source": [
        "summarize_errors(val_multi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g3WkTevPkZ7Y",
      "metadata": {
        "id": "g3WkTevPkZ7Y"
      },
      "source": [
        "##### **2. Define Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SGQr9s5dWMWO",
      "metadata": {
        "id": "SGQr9s5dWMWO"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "### Define Neural Network Model\n",
        "###########################################################################\n",
        "\n",
        "class Model(nn.Module):  ## subclass nn.Module\n",
        "    ## input size: number of features (X variables), dimension of X\n",
        "    ## hidden-size: number of nodes in hidden layers\n",
        "    ## output_size: dimension of y\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        ## nn.Linear: a linear transformation,a.k.a a fully connected layer or a dense layer to implement summation junction\n",
        "        ## define two hidden layers, layer1 and layer2\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)   ## layer 1 has \"input_size\" number of input nodes and \"hidden_size\" number of output nodes\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)  ## layer 2 has \"hidden_size\" number of input nodes and \"output_size\" number of output nodes\n",
        "        self.activation = nn.ReLU()  # Use ReLU for hidden layer\n",
        "\n",
        "    ## forward() method that must be defined within any class that subclasses torch.nn.Module.\n",
        "    ## This method defines the computational graph of a neural network,\n",
        "    ## outlining how input data is processed through the network's layers to produce an output.\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.layer1(x))  # Apply ReLU to hidden layer\n",
        "        x = self.layer2(x)                   # Linear output for regression\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q0bLDt2KWRjk",
      "metadata": {
        "id": "Q0bLDt2KWRjk"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "### Helper functions, validation with days prior 1-30\n",
        "###########################################################################\n",
        "\n",
        "def prepare_data(train_df, val_df, feature_cols, target_col):\n",
        "    \"\"\"Prepare train and val sets\"\"\"\n",
        "    val_df = val_df[val_df['days_prior'].between(1, 30)].copy()\n",
        "    X_train = pd.get_dummies(train_df[feature_cols], columns=[\"day_of_week\"], drop_first=True)\n",
        "    X_val = pd.get_dummies(val_df[feature_cols], columns=[\"day_of_week\"], drop_first=True)\n",
        "    X_train, X_val = X_train.align(X_val, join=\"left\", axis=1, fill_value=0)\n",
        "\n",
        "    y_train = train_df[target_col].to_numpy().astype(np.float32)\n",
        "    y_val = val_df[target_col].to_numpy().astype(np.float32)\n",
        "\n",
        "    return X_train.to_numpy().astype(np.float32), y_train, X_val.to_numpy().astype(np.float32), y_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B0PrO1_Th2Vk",
      "metadata": {
        "id": "B0PrO1_Th2Vk"
      },
      "source": [
        "##### Normalize data, convert to tensors, create DataLoader, setup loss function and optimizer, train model, and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5IDB1DU0WUsv",
      "metadata": {
        "id": "5IDB1DU0WUsv"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, X_test, y_test, num_epochs=10, hidden_size=20, lr=0.001):\n",
        "    \"\"\"Train and evaluate model for one hotel.\"\"\"\n",
        "    # Normalize\n",
        "    X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n",
        "    X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train_t = torch.from_numpy(X_train_norm).float()\n",
        "    y_train_t = torch.from_numpy(y_train).float()\n",
        "    X_test_t = torch.from_numpy(X_test_norm).float()\n",
        "    y_test_t = torch.from_numpy(y_test).float()\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "    train_dl = DataLoader(train_ds, batch_size=20, shuffle=True)\n",
        "\n",
        "    # Model setup\n",
        "    input_size = X_train_t.shape[1]\n",
        "    model = Model(input_size, hidden_size, 1)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for xb, yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred.squeeze(), yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_dl):.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_test_t).squeeze()\n",
        "        mse = loss_fn(preds, y_test_t)\n",
        "        rmse = torch.sqrt(mse).item()\n",
        "\n",
        "    print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "    return model, preds.numpy(), rmse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U4p8ZInKDdLR",
      "metadata": {
        "id": "U4p8ZInKDdLR"
      },
      "source": [
        "##### Loop through hotels and run model + error summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7WdLM8tWV4p",
      "metadata": {
        "id": "b7WdLM8tWV4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b90a48-4705-4f24-dd2d-d74774a34d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:38: SyntaxWarning: invalid escape sequence '\\A'\n",
            "<>:38: SyntaxWarning: invalid escape sequence '\\A'\n",
            "/tmp/ipython-input-750035624.py:38: SyntaxWarning: invalid escape sequence '\\A'\n",
            "  print(\"\\All models: \")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== G ==\n",
            "Epoch 1/10, Loss: 1229.9921\n",
            "Epoch 2/10, Loss: 647.4254\n",
            "Epoch 3/10, Loss: 631.5223\n",
            "Epoch 4/10, Loss: 622.6189\n",
            "Epoch 5/10, Loss: 617.6654\n",
            "Epoch 6/10, Loss: 613.7890\n",
            "Epoch 7/10, Loss: 610.0596\n",
            "Epoch 8/10, Loss: 606.2392\n",
            "Epoch 9/10, Loss: 601.8015\n",
            "Epoch 10/10, Loss: 597.8620\n",
            "Validation RMSE: 17.6850\n",
            "\n",
            "== M ==\n",
            "Epoch 1/10, Loss: 2718.0788\n",
            "Epoch 2/10, Loss: 2302.4971\n",
            "Epoch 3/10, Loss: 2288.5612\n",
            "Epoch 4/10, Loss: 2276.8740\n",
            "Epoch 5/10, Loss: 2266.5360\n",
            "Epoch 6/10, Loss: 2256.8505\n",
            "Epoch 7/10, Loss: 2247.1827\n",
            "Epoch 8/10, Loss: 2237.3794\n",
            "Epoch 9/10, Loss: 2227.0584\n",
            "Epoch 10/10, Loss: 2215.6422\n",
            "Validation RMSE: 40.4877\n",
            "\n",
            "== W ==\n",
            "Epoch 1/10, Loss: 1592.6196\n",
            "Epoch 2/10, Loss: 1285.5900\n",
            "Epoch 3/10, Loss: 1269.8231\n",
            "Epoch 4/10, Loss: 1256.4038\n",
            "Epoch 5/10, Loss: 1242.0344\n",
            "Epoch 6/10, Loss: 1226.7056\n",
            "Epoch 7/10, Loss: 1211.0253\n",
            "Epoch 8/10, Loss: 1196.2281\n",
            "Epoch 9/10, Loss: 1184.1455\n",
            "Epoch 10/10, Loss: 1173.6146\n",
            "Validation RMSE: 24.3681\n",
            "\\All models: \n",
            "\n",
            "OVERALL METRICS:\n",
            "MAE:  23.10\n",
            "MAPE: 0.35%\n",
            "MASE: 1.17\n",
            "\n",
            "===== G =====\n",
            "\n",
            "Average Errors by Month:\n",
            " Month  Average MAE  Average MAPE  Average MASE\n",
            "     2    14.195621      0.175709      0.673819\n",
            "     3    15.804392      0.197262      0.750182\n",
            "     4    12.653224      0.142027      0.600606\n",
            "\n",
            "Average Errors by Days-Prior Range:\n",
            "Days-Prior Range  Average MAE  Average MAPE  Average MASE\n",
            "             1-7    16.641922      0.225022      0.789937\n",
            "            8-14    13.144251      0.162382      0.623914\n",
            "           15-21    13.000663      0.148844      0.617098\n",
            "           22-30    14.174918      0.155793      0.672836\n",
            "\n",
            "===== M =====\n",
            "\n",
            "Average Errors by Month:\n",
            " Month  Average MAE  Average MAPE  Average MASE\n",
            "     2    32.421020      0.449929      1.751956\n",
            "     3    35.754829      0.440737      1.932107\n",
            "     4    36.953113      0.515543      1.996859\n",
            "\n",
            "Average Errors by Days-Prior Range:\n",
            "Days-Prior Range  Average MAE  Average MAPE  Average MASE\n",
            "             1-7    27.716660      0.461757      1.497743\n",
            "            8-14    33.795240      0.453648      1.826215\n",
            "           15-21    37.817143      0.473077      2.043549\n",
            "           22-30    39.777099      0.482884      2.149461\n",
            "\n",
            "===== W =====\n",
            "\n",
            "Average Errors by Month:\n",
            " Month  Average MAE  Average MAPE  Average MASE\n",
            "     2    21.440546      0.403147      1.014465\n",
            "     3    17.490868      0.306725      0.827585\n",
            "     4    21.089322      0.555383      0.997847\n",
            "\n",
            "Average Errors by Days-Prior Range:\n",
            "Days-Prior Range  Average MAE  Average MAPE  Average MASE\n",
            "             1-7    15.944903      0.376665      0.754437\n",
            "            8-14    19.130829      0.375764      0.905180\n",
            "           15-21    21.225097      0.426685      1.004271\n",
            "           22-30    22.698552      0.485835      1.073988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-195076159.py:105: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  df.groupby(['hotel_code', 'days_prior_range'])\n"
          ]
        }
      ],
      "source": [
        "###########################################################################\n",
        "### Loop through hotels and run model + error summaries\n",
        "###########################################################################\n",
        "all_results = []\n",
        "\n",
        "for hotel in df['hotel_code'].unique():\n",
        "    print(f\"\\n== {hotel} ==\")\n",
        "    train_hotel = train[train['hotel_code'] == hotel]\n",
        "    val_hotel = val[val['hotel_code'] == hotel]\n",
        "\n",
        "    if len(train_hotel) < 10 or len(val_hotel) < 10:\n",
        "        print(\"Not enough data, skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, y_train, X_val, y_val = prepare_data(train_hotel, val_hotel, feature_cols, target_col)\n",
        "\n",
        "    # Train model\n",
        "    model, y_pred, rmse = train_model(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Compute and store errors\n",
        "    val_hotel = val_hotel[val_hotel['days_prior'].between(1, 30)].copy()\n",
        "    val_hotel = val_hotel.copy()\n",
        "    val_hotel['pred'] = y_pred\n",
        "    val_hotel['abs_error'] = np.abs(val_hotel['pred'] - val_hotel['final_demand'])\n",
        "    val_hotel['mae'] = val_hotel['abs_error']\n",
        "    val_hotel['mape'] = val_hotel['abs_error'] / (val_hotel['final_demand'] + 1e-8)\n",
        "    val_hotel['rmse'] = rmse\n",
        "\n",
        "    # Compute MASE\n",
        "    val_hotel = compute_mase(val_hotel, train_hotel)\n",
        "\n",
        "    # Append\n",
        "    all_results.append(val_hotel)\n",
        "\n",
        "# Combine all hotel results\n",
        "final_results = pd.concat(all_results, ignore_index=True)\n",
        "print(\"\\All models: \")\n",
        "\n",
        "# Summarize errors across all hotels\n",
        "summarize_errors(final_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "naSlck6JY_lW",
      "metadata": {
        "id": "naSlck6JY_lW"
      },
      "source": [
        "\n",
        "##### **Time Series LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q9sJKmKbuW0u",
      "metadata": {
        "id": "q9sJKmKbuW0u"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "### Define neural network model class by subclassing nn.Module\n",
        "###########################################################################\n",
        "##### Define a LSTM Model - LSTM layer + linear layer\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.linear(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') ## get the device information\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Okc90sGRDj_O",
      "metadata": {
        "id": "Okc90sGRDj_O"
      },
      "source": [
        "##### Reshape data and convert to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcAZETwhum4X",
      "metadata": {
        "id": "dcAZETwhum4X"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, lookback=100):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i+lookback])\n",
        "        y.append(data[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def prepare_data(df, hotel_code):\n",
        "    hotel_df = df[df[\"hotel_code\"] == hotel_code].copy()\n",
        "    hotel_df = hotel_df.set_index(\"stay_date\").asfreq(\"D\").fillna(method=\"ffill\")\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(hotel_df[[\"final_demand\"]])\n",
        "    return hotel_df, scaled, scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EKZxvMKUDq1N",
      "metadata": {
        "id": "EKZxvMKUDq1N"
      },
      "source": [
        "##### Loop through each hotel and apply Time Series LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NHd2_kCFeJ8r",
      "metadata": {
        "id": "NHd2_kCFeJ8r"
      },
      "outputs": [],
      "source": [
        "# Filter relevant columns\n",
        "df = df[[\"stay_date\", \"final_demand\", \"hotel_code\"]].drop_duplicates()\n",
        "\n",
        "# Split train/test\n",
        "train_df = df[df[\"stay_date\"] < \"2010-01-01\"]\n",
        "test_df  = df[(df[\"stay_date\"] >= \"2010-01-01\") & (df[\"stay_date\"] <= \"2010-04-30\")]\n",
        "\n",
        "# Combine for continuous indexing (needed for lookback)\n",
        "df = pd.concat([train_df, test_df]).sort_values(\"stay_date\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kX1I2ZNVetQK",
      "metadata": {
        "id": "kX1I2ZNVetQK"
      },
      "outputs": [],
      "source": [
        "input_size = 1\n",
        "num_layers = 2\n",
        "hidden_size = 100\n",
        "output_size = 1\n",
        "dropout = 0  # Added dropout for regularization\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RVQQAxAOeaP-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "collapsed": true,
        "id": "RVQQAxAOeaP-",
        "outputId": "721df250-2d8d-4b1d-a38e-4cb5b47a7074"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2720528048.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  hotel_df = hotel_df.set_index(\"stay_date\").asfreq(\"D\").fillna(method=\"ffill\")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-785007649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3319725865.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # @title\n",
        "# lookback = 50\n",
        "# forecast_horizon = 30\n",
        "# asof_start = pd.to_datetime(\"2010-01-30\")\n",
        "# asof_end   = pd.to_datetime(\"2010-03-31\")\n",
        "\n",
        "# asof_dates = pd.date_range(asof_start, asof_end, freq=\"D\")\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for hotel in df[\"hotel_code\"].unique():\n",
        "#     hotel_df, scaled, scaler = prepare_data(df, hotel)\n",
        "#     demand_series = scaled.flatten()\n",
        "\n",
        "#     for asof_date in asof_dates:\n",
        "#         # Only use data up to as-of date\n",
        "#         mask = hotel_df.index <= asof_date\n",
        "#         train_series = demand_series[mask]\n",
        "\n",
        "#         if len(train_series) < lookback:\n",
        "#             continue  # skip if not enough history\n",
        "\n",
        "#         # Create sequences\n",
        "#         X_train, y_train = create_sequences(train_series, lookback)\n",
        "#         X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
        "#         y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "#         # Use the model initialized outside the loop\n",
        "#         # model = LSTMModel() # Removed this line\n",
        "#         criterion = nn.MSELoss()\n",
        "#         optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "#         model.train()\n",
        "#         for epoch in range(20):\n",
        "#             optimizer.zero_grad()\n",
        "#             y_pred = model(X_train)\n",
        "#             loss = criterion(y_pred, y_train)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#         # Forecast next 30 days iteratively\n",
        "#         model.eval()\n",
        "#         last_input = train_series[-lookback:].reshape(1, lookback, 1)\n",
        "#         last_input = torch.tensor(last_input, dtype=torch.float32)\n",
        "#         preds = []\n",
        "\n",
        "#         for dp in range(forecast_horizon):\n",
        "#             with torch.no_grad():\n",
        "#                 pred = model(last_input).item()\n",
        "#                 preds.append(pred)\n",
        "#                 last_input = torch.cat([last_input[:, 1:, :],\n",
        "#                                         torch.tensor([[[pred]]])], dim=1)\n",
        "\n",
        "#         preds_rescaled = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
        "#         forecast_dates = pd.date_range(asof_date + pd.Timedelta(days=1),\n",
        "#                                        asof_date + pd.Timedelta(days=forecast_horizon))\n",
        "\n",
        "#         results.append(pd.DataFrame({\n",
        "#             \"hotel_code\": hotel,\n",
        "#             \"asof_date\": asof_date,\n",
        "#             \"forecast_date\": forecast_dates,\n",
        "#             \"forecast_demand\": preds_rescaled\n",
        "#         }))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6DVENRBgl21W",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DVENRBgl21W",
        "outputId": "cfd7e498-fe01-4947-f18d-07c7f6830a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n",
            "\n",
            "Training once for hotel G ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2720528048.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  hotel_df = hotel_df.set_index(\"stay_date\").asfreq(\"D\").fillna(method=\"ffill\")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "lookback = 50\n",
        "forecast_horizon = 30\n",
        "asof_dates = pd.date_range(\"2010-01-30\", \"2010-03-31\", freq=\"D\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for hotel in df[\"hotel_code\"].unique():\n",
        "    print(f\"\\nTraining once for hotel {hotel} ...\")\n",
        "    hotel_df, scaled, scaler = prepare_data(df, hotel)\n",
        "    demand_series = scaled.flatten()\n",
        "\n",
        "    # Train only up to 2010-01-01\n",
        "    train_mask = hotel_df.index < \"2010-01-01\"\n",
        "    train_series = demand_series[train_mask]\n",
        "    X_train, y_train = create_sequences(train_series, lookback)\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1).to(device)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1).to(device)\n",
        "\n",
        "    input_size = 1\n",
        "    num_layers = 5\n",
        "    hidden_size = 32\n",
        "    output_size = 1\n",
        "    dropout = 0.2\n",
        "\n",
        "    model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size, dropout=dropout).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    print(\"⏳ Training model ...\")\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"✅ Done training.\\n\")\n",
        "\n",
        "    # --- Rolling as-of-date forecasts ---\n",
        "    model.eval()\n",
        "    for asof_date in tqdm(asof_dates, desc=f\"Rolling forecasts for {hotel}\"):\n",
        "        # use all data available up to that as-of date\n",
        "        mask = hotel_df.index <= asof_date\n",
        "        full_series = demand_series[mask]\n",
        "\n",
        "        if len(full_series) < lookback:\n",
        "            continue\n",
        "\n",
        "        last_input = full_series[-lookback:].reshape(1, lookback, 1)\n",
        "        last_input = torch.tensor(last_input, dtype=torch.float32).to(device)\n",
        "        preds = []\n",
        "\n",
        "        for dp in range(forecast_horizon):\n",
        "            with torch.no_grad():\n",
        "                pred = model(last_input).item()\n",
        "                preds.append(pred)\n",
        "                new_input = torch.tensor([[[pred]]], dtype=torch.float32).to(device)\n",
        "                last_input = torch.cat([last_input[:, 1:, :], new_input], dim=1)\n",
        "\n",
        "        preds_rescaled = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
        "        forecast_dates = pd.date_range(asof_date + pd.Timedelta(days=1),\n",
        "                                       asof_date + pd.Timedelta(days=forecast_horizon))\n",
        "\n",
        "        tmp = pd.DataFrame({\n",
        "            \"hotel_code\": hotel,\n",
        "            \"as_of_date\": asof_date,\n",
        "            \"stay_date\": forecast_dates,\n",
        "            \"days_prior\": np.arange(1, forecast_horizon + 1),\n",
        "            \"fcst\": preds_rescaled\n",
        "        })\n",
        "        results.append(tmp)\n",
        "\n",
        "forecast_df = pd.concat(results).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lA4jCG--efSN",
      "metadata": {
        "id": "lA4jCG--efSN"
      },
      "outputs": [],
      "source": [
        "forecast_df = pd.concat(results).reset_index(drop=True)\n",
        "\n",
        "# Merge with actual demand\n",
        "actuals = df[[\"stay_date\", \"hotel_code\", \"final_demand\"]]\n",
        "forecast_df = forecast_df.merge(actuals, left_on=[\"forecast_date\",\"hotel_code\"],\n",
        "                                right_on=[\"stay_date\",\"hotel_code\"], how=\"left\")\n",
        "\n",
        "# Compute errors\n",
        "forecast_df[\"abs_error\"] = abs(forecast_df[\"forecast_demand\"] - forecast_df[\"final_demand\"])\n",
        "forecast_df[\"mape\"] = forecast_df[\"abs_error\"] / (forecast_df[\"final_demand\"] + 1e-8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kvbx8HjH6LIV",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "kvbx8HjH6LIV",
        "outputId": "1acfb994-e391-4cc4-c298-f1e920d70c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "========== HOTEL: G ==========\n",
            "Epoch [10/50] - Train Loss: 0.0258\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3211174434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# ###########################################################################\n",
        "# ### Main loop over hotel codes\n",
        "# ###########################################################################\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(\"Using device:\", device)\n",
        "\n",
        "# # Prepare data\n",
        "# df = df[[\"stay_date\", \"final_demand\", \"hotel_code\"]].drop_duplicates()\n",
        "# df[\"stay_date\"] = pd.to_datetime(df[\"stay_date\"])\n",
        "# hotel_codes = df[\"hotel_code\"].unique()\n",
        "\n",
        "# # Loop through each hotel\n",
        "# for code in hotel_codes:\n",
        "#     print(f\"\\n========== HOTEL: {code} ==========\")\n",
        "#     hotel_df = df[df[\"hotel_code\"] == code].sort_values(\"stay_date\")\n",
        "\n",
        "#     # Split train/test by date\n",
        "#     train_data = hotel_df[hotel_df[\"stay_date\"] < \"2010-01-01\"].copy()\n",
        "#     test_data = hotel_df[hotel_df[\"stay_date\"] >= \"2010-01-01\"].copy()\n",
        "\n",
        "#     # Prepare dataset (only final_demand)\n",
        "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#     dataset_train = scaler.fit_transform(train_data[[\"final_demand\"]])\n",
        "#     dataset_test = scaler.transform(test_data[[\"final_demand\"]])\n",
        "\n",
        "#     # Prepare dataloaders\n",
        "#     sequence_length = 30\n",
        "#     batch_size = 32\n",
        "\n",
        "#     train_loader = prepare_timeseries_dataloader(dataset_train, sequence_length, batch_size, shuffle=True)\n",
        "#     test_loader = prepare_timeseries_dataloader(dataset_test, sequence_length, batch_size, shuffle=False)\n",
        "\n",
        "#     # Define model\n",
        "#     input_size = 1\n",
        "#     hidden_size = 128\n",
        "#     num_layers = 2\n",
        "#     output_size = 1\n",
        "#     dropout = 0.2\n",
        "\n",
        "#     model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout).to(device)\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "#     loss_fn = nn.MSELoss()\n",
        "\n",
        "#     # Train model\n",
        "#     num_epochs = 50\n",
        "#     for epoch in range(num_epochs):\n",
        "#         model.train()\n",
        "#         total_loss = 0\n",
        "#         for batch_X, batch_y in train_loader:\n",
        "#             batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             preds = model(batch_X)\n",
        "#             loss = loss_fn(preds, batch_y)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item()\n",
        "\n",
        "#         if (epoch + 1) % 10 == 0:\n",
        "#             avg_loss = total_loss / len(train_loader)\n",
        "#             print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#     ###########################################################################\n",
        "#     ### Forecast\n",
        "#     ###########################################################################\n",
        "#     model.eval()\n",
        "#     test_series = dataset_test.flatten()\n",
        "#     last_sequence = test_series[-sequence_length:]  # last 30 days\n",
        "#     forecasted_values = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for _ in range(30):  # predict next 30 days\n",
        "#             seq_input = torch.tensor(last_sequence).float().view(1, -1, 1).to(device)\n",
        "#             pred = model(seq_input).cpu().item()\n",
        "#             forecasted_values.append(pred)\n",
        "#             last_sequence = np.append(last_sequence[1:], pred)\n",
        "\n",
        "#     # Inverse transform\n",
        "#     forecasted_values = scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()\n",
        "#     actual_values = test_data[\"final_demand\"].values[-30:]\n",
        "#     future_dates = pd.date_range(start=test_data[\"stay_date\"].iloc[-1] + pd.Timedelta(days=1), periods=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zub7wvW5KKRV",
      "metadata": {
        "id": "zub7wvW5KKRV"
      },
      "source": [
        "##### **LTSM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZEtrQbv_NCg"
      },
      "id": "OZEtrQbv_NCg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}